# -*- coding: utf-8 -*-
"""SuperStore Sales: Data Process and Visualization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-9OtWa_sQMQesXdcCKfl6y7ag-AHzX9p

#**Week-6 Assignment-2**
##**SuperStore Sales: Data Processing and Visualization**
### *By Arijit Dhali [Linkedin](https://www.linkedin.com/in/arijit-dhali-b255b0138/)*

---
Retail dataset of a global superstore for 4 years. Perform Exploratory Data Analysis. Here we follow the step for univariate and bivariate data analysis on the SuperStore Sales dataset:

# **Importing Libraries**

So, inorder to perform anything on the data we must require to import the librarires first and set the diplay view of the dataset.

This code snippet imports necessary Python libraries, `sets display options for Pandas`, and prepares the environment for data analysis and visualization.
"""

# Importing necessary libraries for data analysis and visualization
import pandas as pd                             # Pandas for data manipulation and analysis
import numpy as np                              # NumPy for numerical operations
import matplotlib.pyplot as plt                 # Matplotlib for basic plotting
import seaborn as sns                           # Seaborn for statistical data visualization
from statsmodels.tsa.seasonal import seasonal_decompose   # For decomposing time series data
import plotly.express as px                     # Plotly Express for interactive visualizations

# Setting display options to show three decimal places for floating-point numbers in Pandas
pd.set_option('display.float_format', lambda x: '%.3f' % x)

"""# **Loading Dataset**

After importing librarires, we will import the data using `GitHub` link of raw file

Continuing the setup for data analysis by adjusting `Pandas display options` and then loads a dataset from a `URL` into a `Pandas` DataFrame.
"""

# Display all columns without truncation
pd.set_option('display.max_columns', None)

# Load car-related dataset from URL into 'stores' DataFrame
url = 'https://raw.githubusercontent.com/ArijitDhali/PrepInsta-DA-Week-6/main/train.csv'
stores = pd.read_csv(url, encoding='unicode_escape')

# Display first two rows of the loaded DataFrame
stores.head(2)

"""In this code, we are removing the '`Row ID`' column from the '`stores`' DataFrame and then displaying the first two rows of the modified DataFrame."""

# Remove 'Row ID' column from 'stores' DataFrame
del stores["Row ID"]

# Display first two rows
stores.head(2)

"""# **Preliminary Data Inspection**

This code is showing the data types of columns in the '`stores`' DataFrame.
"""

# Display data types of columns in the 'stores' DataFrame
stores.dtypes

"""Here, we are displaying detailed information about the '`stores`' DataFrame, including data types and memory usage."""

# Display concise information about the 'stores' DataFrame, including data types and memory usage
stores.info(verbose=True)

"""This code is showing the number of rows and columns in the '`stores`' DataFrame."""

stores.shape         # Display the shape (rows, columns)

"""Here, we are generating descriptive statistics, such as **mean, standard deviation, minimum, and maximum values**, for numerical columns in the '`stores`' DataFrame."""

stores.describe()      # Generate descriptive statistics for numerical columns

"""# **Data Cleaning and Viewing**

### 1. Handling the missing values and standardizing `Date` values

This code checks for duplicate rows in the '`stores`' DataFrame and calculates the total number of duplicate rows.
"""

# Check for duplicate rows in 'stores' DataFrame
stores.duplicated().sum()

"""In this code, we are removing duplicate rows from the '`stores`' DataFrame, and then checking again to ensure that there are no remaining duplicates."""

# Drop duplicate rows from the 'stores' DataFrame
stores = stores.drop_duplicates()
stores.duplicated().sum()

"""Here, the code checks for missing values in the '`stores`' DataFrame and provides the count of `null values` for each column."""

# Check if there are any missing values in the data
stores.isnull().sum()

"""This code shows the rows in the '`stores`' DataFrame where the '`Postal Code`' column has null (`missing`) values."""

stores[stores['Postal Code'].isnull()]      # Display rows where 'Postal Code' is null

"""After looking on website, the postal code for Burlington, Vermont is given as 05401 [Reference](https://www.google.com/search?q=Vermont+Burlington+east+postal+address&sca_esv=597572708&sxsrf=ACQVn0-ZS95Q2bl-ziWujQAU7T9MsM3U3w%3A1704999539952&ei=czqgZbfdObKfseMP1L634AM&ved=0ahUKEwj34q6fgtaDAxWyT2wGHVTfDTwQ4dUDCBA&uact=5&oq=Vermont+Burlington+east+postal+address&gs_lp=Egxnd3Mtd2l6LXNlcnAiJlZlcm1vbnQgQnVybGluZ3RvbiBlYXN0IHBvc3RhbCBhZGRyZXNzMgoQABhHGNYEGLADMgoQABhHGNYEGLADMgoQABhHGNYEGLADMgoQABhHGNYEGLADMgoQABhHGNYEGLADMgoQABhHGNYEGLADMgoQABhHGNYEGLADMgoQABhHGNYEGLADSKsHUCJY6wRwAXgBkAEAmAHCAaABqgSqAQMwLjO4AQPIAQD4AQHiAwQYACBBiAYBkAYI&sclient=gws-wiz-serp)

In this code, we are replacing null values in the '`Postal Code`' column of the '`stores`' DataFrame with the value `5401`, and then checking again for any remaining missing values.
"""

# Replace null values in the 'Postal Code' column of the 'stores' DataFrame with 5401
stores['Postal Code'] = stores['Postal Code'].replace(np.nan, 5401)

# Check for missing values after the replacement
stores.isnull().sum()

"""Here, we are showing the updated number of rows and columns in the '`stores`' DataFrame after the previous data manipulation steps."""

stores.shape         # Display the current shape (rows, columns)

"""This code converts the '`Order Date`' column in the '`stores`' DataFrame to the standard date format '`YYYY-MM-DD`' using the `pd.to_datetime` function and displays the updated 'Order Date' column."""

# Convert 'Order Date' to the standard format 'YYYY-MM-DD'
stores['Order Date'] = pd.to_datetime(stores['Order Date'], format='%d/%m/%Y')
stores['Order Date']

"""In this code, we are converting the '`Ship Date`' column in the 'stores' DataFrame to the standard date format '`YYYY-MM-DD`' using the `pd.to_datetime` function and displaying the updated '`Ship Date`' column."""

# Convert 'Ship Date' to the standard format 'YYYY-MM-DD'
stores['Ship Date'] = pd.to_datetime(stores['Ship Date'], format='%d/%m/%Y')
stores['Ship Date']

"""This code calculates the number of days taken to ship by subtracting the '`Order Date`' from the '`Ship Date`' in the '`stores`' DataFrame, and then creates a new column named '`Days to Ship`' to store these calculated values."""

# Calculate the days taken to ship and create a new 'Days to Ship' column in the 'stores' DataFrame
stores['Days to Ship'] = (stores['Ship Date'] - stores['Order Date']).dt.days
stores['Days to Ship']

"""Here, we are moving the '`Days to Ship`' column to index 2 in the '`stores`' DataFrame. This repositions the column in the specified index while maintaining the order of other columns."""

# Move 'Days to Ship' column to index 2
column_to_move = 'Days to Ship'
stores.insert(3, column_to_move, stores.pop(column_to_move))

"""This code shows a random sample of one row from the '`stores`' DataFrame."""

# Display a random sample of one row from the 'stores' DataFrame
stores.sample()

"""### 2. Viewing `Order ID` Dataset

This code prints the unique values and the total number of unique values in the '`Order ID`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Order ID' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Order ID'].unique())
print('Total Number of Unique Values: ', stores['Order ID'].nunique())

"""### 3. Viewing `Order Date` Dataset

This code prints the unique values and the total number of unique values in the '`Order Date`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Order Date' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Order Date'].unique())
print('Total Number of Unique Values: ', stores['Order Date'].nunique())

"""### 4. Viewing `Ship Date` Dataset

This code prints the unique values and the total number of unique values in the '`Ship Date`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Ship Date' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Ship Date'].unique())
print('Total Number of Unique Values: ', stores['Ship Date'].nunique())

"""### 5. Viewing `Days to Ship` Dataset

This code prints the unique values and the total number of unique values in the '`Days to Ship`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Days to Ship' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Days to Ship'].unique())
print('Total Number of Unique Values: ', stores['Days to Ship'].nunique())

"""### 6. Viewing `Customer ID` Dataset

This code prints the unique values and the total number of unique values in the '`Customer ID`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Customer ID' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Customer ID'].unique())
print('Total Number of Unique Values: ', stores['Customer ID'].nunique())

"""### 7. Viewing `Customer Name` Dataset

This code prints the unique values and the total number of unique values in the '`Customer Name`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Customer Name' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Customer Name'].unique())
print('Total Number of Unique Values: ', stores['Customer Name'].nunique())

"""### 8. Viewing `Segment` Dataset

This code prints the unique values and the total number of unique values in the '`Segment`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Segment' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Segment'].unique())
print('Total Number of Unique Values: ', stores['Segment'].nunique())

"""### 9. Viewing `Country` Dataset

This code prints the unique values and the total number of unique values in the '`Country`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Country' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Country'].unique())
print('Total Number of Unique Values: ', stores['Country'].nunique())

"""### 10. Viewing `City` Dataset

This code prints the unique values and the total number of unique values in the '`City`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'City' column of the 'stores' DataFrame
print('Unique Values: \n', stores['City'].unique())
print('Total Number of Unique Values: ', stores['City'].nunique())

"""### 11. Viewing `State` Dataset

This code prints the unique values and the total number of unique values in the '`State`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'State' column of the 'stores' DataFrame
print('Unique Values: \n', stores['State'].unique())
print('Total Number of Unique Values: ', stores['State'].nunique())

"""### 12. Viewing `Postal Code` Dataset

This code prints the unique values and the total number of unique values in the '`Postal Code`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Postal Code' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Postal Code'].unique())
print('Total Number of Unique Values: ', stores['Postal Code'].nunique())

"""### 13. Viewing `Region` Dataset

This code prints the unique values and the total number of unique values in the '`Region`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Region' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Region'].unique())
print('Total Number of Unique Values: ', stores['Region'].nunique())

"""### 14. Viewing `Product ID` Dataset

This code prints the unique values and the total number of unique values in the '`Product ID`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Product ID' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Product ID'].unique())
print('Total Number of Unique Values: ', stores['Product ID'].nunique())

"""### 15. Viewing `Category` Dataset

This code prints the unique values and the total number of unique values in the '`Category`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Category' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Category'].unique())
print('Total Number of Unique Values: ', stores['Category'].nunique())

"""### 16. Viewing `Sub-Category` Dataset

This code prints the unique values and the total number of unique values in the '`Sub-Category`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Sub-Category' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Sub-Category'].unique())
print('Total Number of Unique Values: ', stores['Sub-Category'].nunique())

"""### 17. Viewing `Product Name` Dataset

This code prints the unique values and the total number of unique values in the '`Product Name`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Product Name' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Product Name'].unique())
print('Total Number of Unique Values: ', stores['Product Name'].nunique())

"""### 18. Viewing `Sales` Dataset

This code prints the unique values and the total number of unique values in the '`Sales`' column of the '`stores`' DataFrame.
"""

# Display unique values and the total number of unique values in the 'Sales' column of the 'stores' DataFrame
print('Unique Values: \n', stores['Sales'].unique())
print('Total Number of Unique Values: ', stores['Sales'].nunique())

"""#**Viewing & Saving Clean Data**

Viewing the final and cleaned data, saving it into `.csv` format

Here, the column names in the '`stores`' DataFrame are modified by replacing spaces with **underscores** and converting them to **lowercase** for consistency.
"""

stores.columns = [col.replace(' ', '_').replace('-', '_').lower() for col in stores.columns] # Rename columns by replacing spaces with underscores and converting to lowercase

"""Now, we take a look at a random sample of 5 rows from the modified '`stores`' DataFrame to observe the changes in column names."""

stores.sample(5)                 # Display a random sample of 5 rows from the modified 'stores' DataFrame

"""This code prints the data types of each column in the modified '`stores`' DataFrame, providing an overview of the data after the column name modifications."""

print(stores.dtypes)       # Display data types of each column in the modified 'stores' DataFrame

"""Here, we print the total number of remaining missing values in the entire modified '`stores`' DataFrame after the data preparation steps."""

print(stores.isnull().sum().sum())               # Sum of all remaining missing values in the modified 'stores' DataFrame

"""Now, we print the current shape of the modified '`stores`' DataFrame, indicating the number of rows and columns after the data preparation steps"""

print(stores.shape)            # Display the current shape (rows, columns) of the modified 'stores' DataFrame

"""This code prints concise information about the modified '`stores`' DataFrame, including **data types, non-null counts, and memory usage**."""

print(stores.info())           # Display concise information about the modified 'stores' DataFrame

"""Here, the modified '`stores`' DataFrame is saved to a **CSV file** named '`stores_data_cleaned.csv`' without including the index column."""

stores.to_csv('stores_data_cleaned.csv', index=False)         # Save the modified 'stores' DataFrame to a CSV file named 'stores_data_cleaned.csv'

"""#**Statistics & Data Vizualization**

## **Data Analysis**

### 1.1. Descriptive Numeric Analysis

This code generates descriptive statistics, such as **mean, standard deviation, minimum, and maximum values**, for numerical columns in the '`stores`' DataFrame.
"""

# Generate descriptive statistics for numerical columns in the 'stores' DataFrame
stores.describe()

"""**Observation:**<br>
Gives a desription about the stats on sale price which is only necessary here.

### 1.2. Descriptive Numeric Analysis

This code generates descriptive statistics for categorical columns in the '`stores`' DataFrame, including **count, unique values, top value, and frequency**.
"""

# Generate descriptive statistics for categorical columns in the 'stores' DataFrame
stores.describe(include=['object'])

"""**Observation:**<br>
Gives an idea about the top values of every column, count and frequency of different values.

### 2. Top Customers:
* Identify the top customers based on total sales or order frequency. This helps in understanding who contributes the most to revenue.

This code identifies and prints the top 5 customers in the '`stores`' DataFrame based on the sum of their sales.
"""

# Find and display the top 5 customers based on the sum of their sales
top_customers = stores.groupby('customer_name')['sales'].sum().sort_values(ascending=False).head(5)
print("Top Customers:\n", top_customers)

"""**Observation:**<br>
Someone should give them some discount for being so loyal to Superstore.
Especially, Sean Miller.

###3. Popular Products:
* Find the most popular products based on sales or order quantity.

This code identifies and prints the top 10 popular products in the '`stores`' DataFrame based on the sum of their sales.
"""

# Find and display the top 10 popular products based on the sum of their sales
popular_products = stores.groupby('product_name')['sales'].sum().sort_values(ascending=False).head(10)
print("Popular Products:\n", popular_products)

"""**Observation:**<br>
Looks like Copier and Binding machine are used so roughly, that they are ordered repeatedly.

### 4. Customer Segmentation:
*  Explore different customer segments and their characteristics.

This code calculates and prints the average sales for each customer segment in the '`stores`' DataFrame.
"""

# Calculate and display the average sales for each customer segment
customer_segmentation = stores.groupby('segment')['sales'].mean()
print("Average Sales by Customer Segment:\n", customer_segmentation)

"""**Observation:**<br>
Looks like everyone opted for work from home.

### 5. Temporal Trends:
*  Analyze trends over time, such as monthly or yearly sales growth.

This code calculates and prints the sum of sales grouped by month, showing temporal trends in the '`stores`' DataFrame.
"""

# Calculate and display the sum of sales grouped by month for temporal trends
temporal_trends = stores.groupby(pd.to_datetime(stores['order_date'], format='%m/%d/%Y').dt.to_period("M"))['sales'].sum()
print("Temporal Trends:\n", temporal_trends)

"""**Observation:**<br>
Datewise analysis of sales happened in every month.

### 6. Geographical Analysis:
*  Examine sales performance across different regions, states, or cities.

This code conducts geographical analysis by calculating and printing the top 10 sales in `regions`, `states`, and `cities` in the '`stores`' DataFrame.
"""

# Perform geographical analysis by calculating and displaying the top 10 sales in regions, states, and cities
geographical_analysis = stores.groupby(['region', 'state', 'city'])['sales'].sum().sort_values(ascending=False).head(10)
print("Geographical Analysis:\n", geographical_analysis)

"""**Observation:**<br>
The company should open its store in New York city and Los Angeles as the sales are higher there.

### 7. Shipping Analysis:
* Investigate the relationship between shipping mode and delivery times.

This code calculates and prints the average days to ship for each shipping mode in the '`stores`' DataFrame.
"""

# Calculate and display the average days to ship for each shipping mode
shipping_analysis = stores.groupby('ship_mode')['days_to_ship'].mean()
print("Average Days to Ship by Shipping Mode:\n", shipping_analysis)

"""**Observation:**<br>
Seems fair. Same day delivery is too impressive.

### 8.Correlation Analysis:
* Explore correlations between numerical variables [ **Correlation isn't necessary for postal code** ].

This code computes and prints the correlation matrix between the '`days_to_ship`' and '`sales`' columns in the '`stores`' DataFrame.
"""

# Calculate and display the correlation matrix between 'days_to_ship' and 'sales' columns
correlation_matrix = stores[['days_to_ship', 'sales']].corr()
print("Correlation Matrix:\n", correlation_matrix)

"""**Observation:**<br>
Gives an analysis of days to ship to sales

### 9. Outliers Detection:
*  Identify and examine outliers in numerical columns.

1.  Outliers for `Sales` Column

This code filters rows in the '`stores`' DataFrame where `sales` are greater than the mean plus three times the standard deviation.
"""

# Filter rows in the 'stores' DataFrame where sales exceed the mean plus 3 times the standard deviation
stores[stores['sales'] > stores['sales'].mean() + 3 * stores['sales'].std()]

"""**Observation:**<br>
Those days were really memorabe for company for having more sales than its used to.

2.  Outliers for `days_to_ship` Column

This code filters rows in the '`stores`' DataFrame where the `days to ship` exceed the mean plus three times the standard deviation.
"""

# Filter rows in the 'stores' DataFrame where days to ship exceed the mean plus 3 times the standard deviation
stores[stores['days_to_ship'] > stores['days_to_ship'].mean() + 3 * stores['days_to_ship'].std()]

"""**Observation:**<br>
Company is more strict to timing

### 10. Average Sales by Category:
*  Showcasing the average Sales by Category:.

This code calculates and prints the average sales for each product category in the 'stores' DataFrame.
"""

# Calculate and display the average sales for each product category
average_sales_by_category = stores.groupby('category')['sales'].mean()
print("Average Sales by Category:\n", average_sales_by_category)

"""**Observation:**<br>
Seems like superstore is popular for its great technology quality.

## **Data Vizualization: `Univariate`**

Here, we set the style of Seaborn plots to '`whitegrid`' for a clean and simple background in visualizations.
"""

# Set the style of Seaborn plots to 'whitegrid'
sns.set(style='whitegrid')

"""### 1. **Histograms**

Create histograms to visualize the distribution of key numeric variables.<br>
Reference: [Link](https://www.geeksforgeeks.org/plotting-histogram-in-python-using-matplotlib/)

Here, we create a side-by-side histogram subplot for the di**stribution of sales and days to ship** in the '`stores`' DataFrame. The visualizations provide insights into the `frequency and patterns` of these **two variables**.
"""

# Create a side-by-side histogram subplot for sales and days to ship
fig, axes = plt.subplots(1, 2, figsize=(14, 4))

# First subplot for sales distribution
sns.histplot(stores['sales'], bins=20, color='skyblue', edgecolor='black', ax=axes[0])
axes[0].set_title('Distribution of Sales')
axes[0].set_xlabel('Sales')
axes[0].set_ylabel('Frequency')
axes[0].set_xlim(0, 20000)
axes[0].set_yscale('log')

# Second subplot for days to ship distribution
sns.histplot(stores['days_to_ship'], bins=20, color='lightcoral', edgecolor='black', ax=axes[1])
axes[1].set_title('Distribution of Days to Ship')
axes[1].set_xlabel('Days to Ship')
axes[1].set_ylabel('Frequency')

# Adjust layout for better spacing
plt.tight_layout()

# Show the visualizations
plt.show()

"""**Observation:**<br>
1. Sales less than 5000 are quiet common.
2. Most shipments take 4 days to ship

### 2. **Time Series Plots**

Plot time series graphs to understand the trends and patterns in sales over the 4-year period.

Here, we create a time series plot for **monthly sales** in the '`stores`' DataFrame. The plot displays the trend in `monthly sales over time` using Seaborn.
"""

# Create a time series plot for monthly sales
plt.figure(figsize=(14, 4))

# Convert 'order_date' to datetime format
stores['order_date'] = pd.to_datetime(stores['order_date'], format='%m/%d/%Y')

# Resample monthly and sum sales
time_series_sales = stores.resample('M', on='order_date')['sales'].sum().reset_index()

# Plot the time series using Seaborn
sns.lineplot(data=time_series_sales, x='order_date', y='sales', marker='o', color='purple')
plt.title('Time Series Plot of Monthly Sales')
plt.xlabel('Date')
plt.ylabel('Monthly Sales')

# Show the plot
plt.show()

"""**Observation:**<br>
We couldn't predict,  but the company seems to earn in last 2 years and tend to grow more.

### 3. **Seasonal Decomposition**

Decompose time series data into components like trend, seasonality, and residuals for deeper insights.<br>
Reference : [Link](https://stackoverflow.com/questions/60017052/decompose-for-time-series-valueerror-you-must-specify-a-period-or-x-must-be)

In this code, we perform seasonal decomposition on the '`sales`' column in the `time_series_sales` DataFrame and plot the `observed, trend, seasonal, and residual` components separately. The resulting visualizations provide insights into the different **aspects of the time series data**.
"""

# Perform seasonal decomposition on the 'sales' column in the time_series_sales DataFrame
result = seasonal_decompose(time_series_sales['sales'], model='additive', period=12)

# Plot individual components
fig, axes = plt.subplots(4, 1, figsize=(14, 8), sharex=True)

axes[0].plot(time_series_sales['order_date'], result.observed, label='Observed', color='blue')
axes[0].legend(loc='upper left')
axes[0].set_title('Observed')

axes[1].plot(time_series_sales['order_date'], result.trend, label='Trend', color='red')
axes[1].legend(loc='upper left')
axes[1].set_title('Trend')

axes[2].plot(time_series_sales['order_date'], result.seasonal, label='Seasonal', color='green')
axes[2].legend(loc='upper left')
axes[2].set_title('Seasonal')

axes[3].plot(time_series_sales['order_date'], result.resid, label='Residual', color='purple')
axes[3].legend(loc='upper left')
axes[3].set_title('Residual')

plt.suptitle('Seasonal Decomposition of Monthly Sales')
plt.tight_layout()
plt.show()

"""**Observation:**<br>
Okay! Now I am sure that company is really growing!

### 4. **Box Plots**

Use box plots to identify outliers and understand the distribution of numeric variables.

Here, we use Seaborn to create a box plot of sales by `category` in the '`stores`' DataFrame. The y-axis is set to a `logarithmic scale` for a better representation of the data distribution.
"""

# Create a box plot of sales by category using Seaborn
plt.figure(figsize=(14, 6))
sns.boxplot(x='category', y='sales', data=stores, palette='viridis')
plt.yscale('log')
plt.title('Box Plot of Sales by Category')
plt.xlabel('Category')
plt.ylabel('Sales (log scale)')
plt.tight_layout()
plt.show()

"""**Observation:**<br>
Outliers seem to be strict.

### 5. **Sales Distribution by Category**

Visualize the distribution of sales across different categories using bar charts or pie charts.

In this code, we calculate the `total sales by category` and create subplots with a `bar plot` and a `pie chart` to visualize the distribution of sales across categories in the 'stores' DataFrame.
"""

# Calculate total sales by category
category_sales = stores.groupby('category')['sales'].sum().reset_index()

# Sort the data by sales in descending order
category_sales = category_sales.sort_values(by='sales', ascending=False)

# Create subplots with two columns
fig, axes = plt.subplots(1, 2, figsize=(10, 4))

# Bar plot on the first subplot
sns.barplot(x='category', y='sales', data=category_sales, palette='crest', ax=axes[0], order=category_sales['category'], width=0.3)
axes[0].set_title('Total Sales by Category')
axes[0].set_xlabel('Category')
axes[0].set_ylabel('Total Sales')

# Pie chart on the second subplot
axes[1].pie(category_sales['sales'], labels=category_sales['category'], autopct='%1.1f%%', colors=sns.color_palette('crest'), startangle=90)
axes[1].set_title('Total Sales by Category')

# Display the plots
plt.tight_layout()
plt.show()

"""**Observation:**<br>
Its interesting to see that Technology has more amount of sale.

### 6. **Sales Variation Over Time**

Plot line charts to observe how sales vary over different time periods (months, quarters, years).

Here, we calculate mo`nthly, quarterly, and yearly sales variations` and create a Seaborn-style line plot to visualize how sales vary over time in the 'stores' DataFrame. The plot displays `monthly, quarterly, and yearly` trends with different colors and markers.
"""

# Calculate monthly, quarterly, and yearly sales variations
monthly_sales_variation = stores.resample('M', on='order_date')['sales'].sum()
quarterly_sales_variation = stores.resample('Q', on='order_date')['sales'].sum()
yearly_sales_variation = stores.resample('Y', on='order_date')['sales'].sum()

# Create a Seaborn-style plot using lineplot
plt.figure(figsize=(14, 5))
sns.lineplot(data=monthly_sales_variation, marker='o', color='blue', label='Monthly')
sns.lineplot(data=quarterly_sales_variation, marker='o', color='green', label='Quarterly')
sns.lineplot(data=yearly_sales_variation, marker='o', color='orange', label='Yearly')

# Set titles and labels
plt.title('Sales Variation Over Time')
plt.xlabel('Date')
plt.ylabel('Sales')

# Add legend
plt.legend()

# Display the plot
plt.show()

"""**Observation:**<br>
For Yearly, its been growing
For month and daily basis, there is a zigzag pattern with a growing trend.

## **Data Vizualization: `Bivariate`**

###1**. Correlation Analysis**

Examine the correlation between sales and other relevant numeric variables.

In this code, we calculate the `correlation matrix for the numeric columns` in the '`stores`' DataFrame and create a `heatmap` using Seaborn to visually represent the correlations between different variables. The `heatmap` includes annotations with correlation values and uses the '`crest`' color map.
"""

# Calculate the correlation matrix
correlation_matrix = stores.corr()

# Create a heatmap using Seaborn
plt.figure(figsize=(5, 5))
sns.heatmap(correlation_matrix, annot=True, cmap='crest', fmt=".2f", linewidths=.5)
plt.title('Correlation Analysis')
plt.tight_layout()
plt.show()

"""**Observation:**<br>
Gives an understanding to sales to shipment days

###2**. Scatter Plots**

Plot scatter plots to explore the relationship between sales and another numeric variable.

This code creates a figure with three scatter plots side by side to compare the `relationships` between `sales and days to ship`, `sales and order year`, and `sales and ship mode` in the '`stores`' DataFrame. Each subplot is labeled with the respective titles and axis labels for clarity.
"""

# Create a figure with three scatter plots side by side
plt.figure(figsize=(18, 6))

# Scatter Plot: Sales vs. Days to Ship
plt.subplot(1, 3, 1)
sns.scatterplot(x='sales', y='days_to_ship', data=stores, color='purple')
plt.title('Sales vs. Days to Ship')
plt.xlabel('Sales')
plt.ylabel('Days to Ship')

# Scatter Plot: Sales vs. Order Date
plt.subplot(1, 3, 2)
sns.scatterplot(x=stores['order_date'].dt.year, y='sales', data=stores, color='blue')
plt.title('Sales vs. Order Year')
plt.xlabel('Order Year')
plt.ylabel('Sales')

# Scatter Plot: Sales vs. Ship Mode
plt.subplot(1, 3, 3)
sns.scatterplot(x='sales', y='ship_mode', data=stores, color='green')
plt.title('Sales vs. Ship Mode')
plt.xlabel('Sales')
plt.ylabel('Ship Mode')

# Adjust layout
plt.tight_layout()
plt.show()

"""**Observation:**<br>
1. It seems that the company is uniform to delivery standards. Order size doesn't priortize the order delivery dates to reduce.
2. In 2018 seem like they are growing with more number of big sales.
3. Most of the sale is a Standard Class Delivery.

###3. **Pair Plots**

Use pair plots for a quick overview of relationships between multiple numeric variables.

Here, we create a pair plot using Seaborn for the numeric variables '`sales`' and '`days_to_ship`' in the '`stores`' DataFrame. The pair plot provides a visual representation of the relationships between these numeric variables.
"""

# Generate a pair plot for selected numeric variables using Seaborn
numeric_columns = ['sales', 'days_to_ship']
sns.pairplot(stores[numeric_columns], height=4, aspect=2)
plt.suptitle('Pair Plot of Numeric Variables', y=1.02)
plt.tight_layout()
plt.show()

"""**Observation:**<br>
Gives analysis to days to ship and sales. They don't depend on each other.

### 4. **Category-wise Sales Trends**

Analyze how sales trends differ across different categories using line charts.<br>
Reference: [`pd.Grouper`](https://stackoverflow.com/questions/55559356/how-do-i-group-date-by-month-using-pd-grouper) Saved my Day 🙂

Here, we convert the '`order_date`' column to datetime format, then resample the data to calculate the `monthly average sales for each category`. The resulting trends are visualized using a line plot with a `logarithmic scale` on the y-axis for better representation.
"""

# Convert 'order_date' to datetime format
stores['order_date'] = pd.to_datetime(stores['order_date'])

# Resample the data to monthly average for each category
monthly_avg_sales = stores.groupby(['category', pd.Grouper(key='order_date', freq='M')])['sales'].mean().reset_index()

# Create a line plot with log scale for the y-axis
plt.figure(figsize=(14, 5))
sns.lineplot(x='order_date', y='sales', hue='category', data=monthly_avg_sales)
plt.yscale('log')
plt.title('Category-wise Sales Trends (Monthly Average)')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.tight_layout()
plt.show()

"""**Observation:**<br>
Shows that Technology is always on demand than that of Furniture and office supplies.

Here, we convert the '`order_date`' column to datetime format and resample the data to calculate the `monthly average sales` for `each sub-category`. The trends are visualized using a line plot with a logarithmic scale on the y-axis using Plotly Express for interactive and detailed exploration.
"""

# Convert 'order_date' to datetime format
stores['order_date'] = pd.to_datetime(stores['order_date'])

# Resample the data to monthly average for each sub_category
monthly_avg_sales = stores.groupby(['sub_category', pd.Grouper(key='order_date', freq='M')])['sales'].mean().reset_index()

# Create a line plot with log scale for the y-axis using Plotly Express
fig = px.line(monthly_avg_sales, x='order_date', y='sales', color='sub_category',
              labels={'sales': 'Sales', 'order_date': 'Date', 'sub_category': 'Sub-Category'},
              title='Sub-Category-wise Sales Trends (Monthly Average)',
              log_y=True, width=1200, height=500)

# Show the plot
fig.show()

"""**Observation:**<br>
I don't know why they need sooooo many copiers and machines for binding.

### 5. **Heatmaps**

Create heatmaps to visualize the correlation matrix for better insights

In this code, we use Seaborn to generate a `heatmap for the correlation matrix`, visualizing the correlations between different variables. The color intensity and annotations provide insights into the **strength and direction** of the correlations.
"""

# Create a heatmap for the correlation matrix using Seaborn
sns.heatmap(correlation_matrix, annot=True, cmap='crest')
plt.title('Correlation Heatmap')
plt.show()

"""**Observation:**<br>
Gives an understanding to sales to shipment days

### 6. **Sales by Region**

Compare sales across different regions using bar charts or stacked bar charts.

In this code, we calculate the `total sales by region` and create subplots with a `bar plot and a pie chart` to visualize the distribution of sales across different regions in the '`stores`' DataFrame.
"""

# Calculate total sales by region
region_sales = stores.groupby('region')['sales'].sum().reset_index()

# Sort the data by sales in descending order
region_sales = region_sales.sort_values(by='sales', ascending=False)

# Create subplots with two columns
fig, axes = plt.subplots(1, 2, figsize=(10, 4))

# Bar plot on the first subplot
sns.barplot(x='region', y='sales', data=region_sales, palette='crest', ax=axes[0], order=region_sales['region'], width=0.3)
axes[0].set_title('Total Sales by Region')
axes[0].set_xlabel('Region')
axes[0].set_ylabel('Total Sales')

# Pie chart on the second subplot
axes[1].pie(region_sales['sales'], labels=region_sales['region'], autopct='%1.1f%%', colors=sns.color_palette('crest'), startangle=90)
axes[1].set_title('Total Sales by Region')

# Display the plots
plt.tight_layout()
plt.show()

"""**Observation:**<br>
People from West region of US order more supplies from superstore then comes East then Central and South

### 7. **Customer Segment Analysis**

Explore sales trends for different customer segments using line charts or bar charts.

Here, we convert the '`order_date`' column to datetime format, resample the data to calculate the `monthly average sales for each customer segment`, and visualize the trends using a line plot with a `logarithmic scale` on the y-axis.
"""

# Convert 'order_date' to datetime format
stores['order_date'] = pd.to_datetime(stores['order_date'])

# Resample the data to monthly average for each segment
monthly_avg_sales = stores.groupby(['segment', pd.Grouper(key='order_date', freq='M')])['sales'].mean().reset_index()

# Create a line plot with log scale for the y-axis
plt.figure(figsize=(14, 5))
sns.lineplot(x='order_date', y='sales', hue='segment', data=monthly_avg_sales)
plt.yscale('log')
plt.title('Customer Segment-wise Sales Trends (Monthly Average)')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.tight_layout()
plt.show()

"""**Observation:**<br>
I guess there is a clash between the manager who wants work from office and employees who want work from home.

### 8. **Sales vs. Quantity**

Investigate the relationship between sales and quantity sold using scatter plots.

Here, we `identify and visualize` the `top 8` selling items by quantity using a `count plot`. The figure width is increased for better presentation of the information.
"""

# Identify the top 8 selling items
top_8_products = stores['product_name'].value_counts().nlargest(8).index

# Create a count plot to visualize the quantity of the top 8 selling items
plt.figure(figsize=(18, 6))  # Increase the width of the figure
sns.countplot(x='product_name', data=stores[stores['product_name'].isin(top_8_products)], order=top_8_products, palette='crest', width=0.3)
plt.title('Top 8 Selling Items By Quantity')
plt.xlabel('Product Name')
plt.ylabel('Quantity')
plt.tight_layout()
plt.show()

"""**Observation:**<br>
Envelop and staples ! I agree, to attach and hide secret documents.

### 9. **Customer Segment vs. Quantity**

Compare the quantity sold across different customer segments using bar charts.

Here, we analyze and `visualize the distribution of customer segments` using a `bar plot and a pie chart`. The bar plot provides a detailed quantity breakdown, while the pie chart offers a proportional representation of customer segments.
"""

# Segment distribution
segment_counts = stores['segment'].value_counts().reset_index()

# Create subplots with two columns
fig, axes = plt.subplots(1, 2, figsize=(10, 4))

# Bar plot on the first subplot
sns.barplot(x='index', y='segment', data=segment_counts, palette='crest', ax=axes[0], width=0.3)
axes[0].set_title('Distribution of Customer Segments')
axes[0].set_xlabel('Customer Segment')
axes[0].set_ylabel('Quantity')

# Pie chart on the second subplot
axes[1].pie(segment_counts['segment'], labels=segment_counts['index'], autopct='%1.1f%%', colors=sns.color_palette('crest'))
axes[1].set_title('Distribution of Customer Segments')

# Display the plots
plt.tight_layout()
plt.show()

"""**Observation:**<br>
The company is mostly B2C as it is customer centric.

### 10. **Shipping Mode vs. Sales**

Explore the relationship between shipping modes and sales using categorical plots.

Here, we analyze and visualize total sales by `shipping mode` using a bar plot. Additionally, we explore the `relationship between ship mode and days to ship` using another bar plot on the second subplot. The second plot helps understand how different `shipping modes affect the time taken to ship products`.
"""

# Analyze total sales by shipping mode
ship_mode_sales = stores.groupby('ship_mode')['sales'].sum().reset_index()

# Sort the data by sales in descending order
ship_mode_sales = ship_mode_sales.sort_values(by='sales', ascending=False)

# Create subplots with two columns
fig, axes = plt.subplots(1, 2, figsize=(14, 4))

# Bar plot for total sales by shipping mode on the first subplot
sns.barplot(x='ship_mode', y='sales', data=ship_mode_sales, palette='crest', ax=axes[0], order=ship_mode_sales['ship_mode'], width=0.3)
axes[0].set_title('Total Sales by Shipping Mode')
axes[0].set_xlabel('Shipping Mode')
axes[0].set_ylabel('Total Sales [in 10 Thousands]')

# Analyze the relationship between ship mode and days to ship
ship_mode_days_to_ship = stores.groupby('ship_mode')['days_to_ship'].mean().reset_index()

# Sort the data by days to ship in descending order
ship_mode_days_to_ship = ship_mode_days_to_ship.sort_values(by='days_to_ship', ascending=False)

# Bar plot for ship mode vs. days to ship on the second subplot
sns.barplot(x='ship_mode', y='days_to_ship', data=stores, ax=axes[1], palette='crest', ci=False, order=ship_mode_days_to_ship['ship_mode'], width=0.3)
axes[1].set_title('Ship Mode vs. Days to Ship')
axes[1].set_xlabel('Ship Mode')
axes[1].set_ylabel('Days to Ship')

# Display the plots
plt.tight_layout()
plt.show()

"""**Observation:**<br>
1. Most people prefer standard class. Who has money for same day deliver?
2. the comany really works hard on their delivery procedure.

### 11. **Product-wise Sales Analysis**

Investigate how sales vary for different products or categories using bar charts or line charts.

Here, we identify and visualize the top `20 products` by sales using a horizontal bar plot. The length of each bar `represents the sales amount`, providing a clear comparison of product performance.
"""

# Identify and visualize the top 20 products by sales with a horizontal bar plot
top_products = stores.groupby('product_name')['sales'].sum().sort_values(ascending=False).head(20).reset_index()

# Create a horizontal bar plot
plt.figure(figsize=(12, 8))
sns.barplot(y='product_name', x='sales', data=top_products, palette='crest')
plt.title('Top 20 Products by Sales')
plt.xlabel('Sales')
plt.ylabel('Product Name')
plt.show()

"""**Observation:**<br>
Again Binder and Copier! Need to catch the person who breaks it !

### 12. **Region-wise Product Sales**

Compare product sales across different regions using grouped bar charts.

Here, we use Plotly Express to create a horizontal bar plot that visualizes `sales by state`. The color of each bar represents the `sales amount`, and the `logarithmic scale` on the x-axis provides a clearer view of the distribution. The layout is adjusted for better presentation.
"""

# Visualize sales by state using a horizontal bar plot with Plotly Express
fig = px.bar(stores, x='sales', y='state', orientation='h', color='sales',
             color_continuous_scale='viridis', error_x=None,
             labels={'sales': 'Sales', 'state': 'States'},
             title='Sales by State',
             log_x=True)

# Adjust the layout
fig.update_layout(height=600, width=1100)

# Display the plot
fig.show()

"""**Observation:**<br>
Looks really messy but Florida and Indiana has most sales

Here, we use Seaborn to create subplots for the `top 10 states` and `cities` by sales. The bar plots are sorted in descending order by sales, and the x-axis is displayed on a logarithmic scale for better visualization of the distribution. The layout is adjusted for a clear presentation.
"""

# Sort the data by sales in descending order and select the top 10 for both states and cities
top_states = stores.sort_values(by='sales', ascending=False).head(10)
top_cities = stores.sort_values(by='sales', ascending=False).head(10)

# Create subplots for states and cities
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Top 10 States
sns.barplot(x='sales', y='state', data=top_states, palette='crest', ci=None, ax=axes[0])
axes[0].set_title('Top 10 States by Sales')
axes[0].set_xlabel('Sales (log scale)')
axes[0].set_ylabel('States')
axes[0].set_xscale('log')

# Top 10 Cities
sns.barplot(x='sales', y='city', data=top_cities, palette='crest', ci=None, ax=axes[1])
axes[1].set_title('Top 10 Cities by Sales')
axes[1].set_xlabel('Sales (log scale)')
axes[1].set_ylabel('Cities')
axes[1].set_xscale('log')

# Adjust layout
plt.tight_layout()
plt.show()

"""**Observation:**<br>
1. Florida, Indiana has most customer base as countries
2. Jacksonville and Lafayette has more customer base as cities

Here, we extract the year from the '`order_date`' column and use Seaborn to create a bar plot illustrating the `yearly sales`. The x-axis represents the years, while the y-axis shows the `total sales for each year`. The bar plot is customized for clear presentation using the 'viridis' color palette.
"""

# Extract the year from the 'order_date' column and create a bar plot for yearly sales
plt.figure(figsize=(5, 4))
sns.barplot(x=stores['order_date'].dt.year, y='sales', data=stores, palette='viridis', width=0.5, estimator=sum, ci=None)
plt.title('Yearly Sales')
plt.xlabel('Year')
plt.ylabel('Sales')
plt.show()

"""**Observation:**<br>
2018 has most sales. that means the company is growing with time really fast.

# **`Bonus`**

**This Graph is just for fun** `DEMONSTRATION`. 🙂

Now, we define a dictionary named `state_codes` that maps each state to its corresponding `two-letter postal code`. This can be useful for various geographical analyses where state codes are preferred over full state names.
"""

# Dictionary mapping states to their corresponding codes
state_codes = {
    'Kentucky': 'KY', 'California': 'CA', 'Florida': 'FL', 'North Carolina': 'NC',
    'Washington': 'WA', 'Texas': 'TX', 'Wisconsin': 'WI', 'Utah': 'UT',
    'Nebraska': 'NE', 'Pennsylvania': 'PA', 'Illinois': 'IL', 'Minnesota': 'MN',
    'Michigan': 'MI', 'Delaware': 'DE', 'Indiana': 'IN', 'New York': 'NY',
    'Arizona': 'AZ', 'Virginia': 'VA', 'Tennessee': 'TN', 'Alabama': 'AL',
    'South Carolina': 'SC', 'Oregon': 'OR', 'Colorado': 'CO', 'Iowa': 'IA',
    'Ohio': 'OH', 'Missouri': 'MO', 'Oklahoma': 'OK', 'New Mexico': 'NM',
    'Louisiana': 'LA', 'Connecticut': 'CT', 'New Jersey': 'NJ', 'Massachusetts': 'MA',
    'Georgia': 'GA', 'Nevada': 'NV', 'Rhode Island': 'RI', 'Mississippi': 'MS',
    'Arkansas': 'AR', 'Montana': 'MT', 'New Hampshire': 'NH', 'Maryland': 'MD',
    'District of Columbia': 'DC', 'Kansas': 'KS', 'Vermont': 'VT', 'Maine': 'ME',
    'South Dakota': 'SD', 'Idaho': 'ID', 'North Dakota': 'ND', 'Wyoming': 'WY',
    'West Virginia': 'WV'
}

"""Atlast, we calculate the `total sales per state`, merge the result with `state codes`, and create a `choropleth map` using Plotly Express. The map visualizes the total sales across different states in the USA, with colors indicating the `sales amount`."""

# Calculate total sales per state and merge with state codes
sales_per_state = stores.groupby('state')['sales'].sum().reset_index()
sales_per_state = sales_per_state.merge(
    pd.DataFrame(list(state_codes.items()), columns=['state', 'state_code']),
    on='state',
    how='left'
)

# Create a choropleth map using Plotly Express
fig = px.choropleth(
    sales_per_state,
    locations='state_code',
    locationmode='USA-states',
    color='sales',
    scope='usa',
    color_continuous_scale='YlOrRd',
    title='Sales per State in the USA',
    labels={'sales': 'Total Sales'},
)

# Show the figure
fig.show()

"""**Observation:**<br>
To make it more interesting. Shows the sales by state!
"""